{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__: 2.8.0\n",
      "keras.__version__: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "# python standard libraries\n",
    "import os\n",
    "import random\n",
    "import fnmatch\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential  # V2 is tensorflow.keras.xxxx, V1 is keras.xxx\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "print( f'tf.__version__: {tf.__version__}' )\n",
    "print( f'keras.__version__: {keras.__version__}' )\n",
    "\n",
    "# imaging\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "# sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    labels = pd.read_csv('data/training_norm.csv')\n",
    "\n",
    "    images_dir = 'data/training_data/'\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    pattern = '*.png'\n",
    "    for label in labels.itertuples():\n",
    "        filename = str(label.image_id) + '.png'\n",
    "\n",
    "        if fnmatch.fnmatch(filename, pattern):\n",
    "            X.append(os.path.join(images_dir, filename))\n",
    "            Y.append([label.angle, label.speed])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    images_dir = 'data/test_data/'\n",
    "    filenames = os.listdir(images_dir)\n",
    "\n",
    "    paths = []\n",
    "    for filename in filenames:\n",
    "        if fnmatch.fnmatch(filename, '*.png'):\n",
    "            paths.append(os.path.join(images_dir, filename))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nvidia_Model\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 16:33:20.119473: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 98, 24)        1824      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 47, 36)        21636     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 22, 48)         43248     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 20, 64)         27712     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 18, 64)         36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               115300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 252,230\n",
      "Trainable params: 252,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def nvidia_model():\n",
    "    model = Sequential(name='Nvidia_Model')\n",
    "    \n",
    "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
    "    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
    "    \n",
    "    # Convolution Layers\n",
    "    model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu')) \n",
    "    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    \n",
    "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # since this is a regression problem not classification problem,\n",
    "    # we use MSE (Mean Squared Error) as loss function\n",
    "    optimizer = Adam(learning_rate=1e-3) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = nvidia_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for NVIDIA model.\n",
    "def img_preprocess(image):\n",
    "    height, _, _ = image.shape\n",
    "    #image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relevant for lane following\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
    "    image = cv2.GaussianBlur(image, (3,3), 0)\n",
    "    image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
    "    image = image / 255 # normalizing\n",
    "    return image\n",
    "\n",
    "def read_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_data_generator(image_paths, angles, batch_size, is_training):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_steering_angles = []\n",
    "\n",
    "        # This works with batches of random images. \n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "\n",
    "            batch_steering_angles.append(angles[random_index])\n",
    "              \n",
    "            image = read_image(image_paths[random_index])\n",
    "            image = img_preprocess(image)\n",
    "            batch_images.append(image)\n",
    "            \n",
    "        yield(np.asarray(batch_images), np.asarray(batch_steering_angles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = 'model_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 11034\n",
      "Validation data: 2759\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0721\n",
      "Epoch 1: val_loss improved from inf to 0.03448, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 307s 1s/step - loss: 0.0721 - val_loss: 0.0345\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 2: val_loss improved from 0.03448 to 0.02594, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 342s 1s/step - loss: 0.0266 - val_loss: 0.0259\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 3: val_loss improved from 0.02594 to 0.01940, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 339s 1s/step - loss: 0.0187 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss did not improve from 0.01940\n",
      "300/300 [==============================] - 363s 1s/step - loss: 0.0159 - val_loss: 0.0199\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01940 to 0.01889, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 295s 987ms/step - loss: 0.0125 - val_loss: 0.0189\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 6: val_loss improved from 0.01889 to 0.01755, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 296s 987ms/step - loss: 0.0114 - val_loss: 0.0176\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 7: val_loss improved from 0.01755 to 0.01734, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 444s 1s/step - loss: 0.0093 - val_loss: 0.0173\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 8: val_loss improved from 0.01734 to 0.01610, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 297s 992ms/step - loss: 0.0094 - val_loss: 0.0161\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 9: val_loss improved from 0.01610 to 0.01570, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 301s 1s/step - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 10: val_loss did not improve from 0.01570\n",
      "300/300 [==============================] - 305s 1s/step - loss: 0.0081 - val_loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "# saves the model weights after each epoch if the validation loss decreased\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(model_output_dir, 'lane_navigation_check.h5'), verbose=1, save_best_only=True)\n",
    "\n",
    "x, y = load_training()\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2)\n",
    "print(\"Training data: %d\\nValidation data: %d\" % (len(x_train), len(x_valid)))\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(image_data_generator(x_train, y_train, batch_size=100, is_training=True),\n",
    "                              steps_per_epoch=300,\n",
    "                              epochs=10,\n",
    "                              validation_data = image_data_generator(x_valid, y_valid, batch_size=100, is_training=False),\n",
    "                              validation_steps=200,\n",
    "                              verbose=1,\n",
    "                              shuffle=1,\n",
    "                              callbacks=[checkpoint_callback, tensorboard_callback])\n",
    "\n",
    "# # always save model output as soon as model finishes training\n",
    "model.save(os.path.join(model_output_dir,'self-drive.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x139fcf910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='blue')\n",
    "plt.plot(history.history['val_loss'],color='red')\n",
    "plt.legend([\"training loss\", \"validation loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse       = 0.017\n",
      "r_squared = 73.91%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def summarize_prediction(Y_true, Y_pred):\n",
    "    mse = mean_squared_error(Y_true, Y_pred)\n",
    "    r_squared = r2_score(Y_true, Y_pred)\n",
    "    print(f'mse       = {mse:.2}')\n",
    "    print(f'r_squared = {r_squared:.2%}')\n",
    "    \n",
    "def predict_and_summarize(X, Y):\n",
    "    model = load_model(f'{model_output_dir}/self-drive.h5')\n",
    "    prediction = model.predict(X)\n",
    "    summarize_prediction(Y, prediction)\n",
    "    return prediction\n",
    "\n",
    "n_tests = 100\n",
    "x_test, y_test = next(image_data_generator(x_valid, y_valid, n_tests, False))\n",
    "y_pred = predict_and_summarize(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_data/348.png\n"
     ]
    }
   ],
   "source": [
    "model = load_model(f'{model_output_dir}/self-drive.h5')\n",
    "        \n",
    "def compute_steering_angle(model, frame):\n",
    "    x = np.asarray([img_preprocess(frame)])\n",
    "    \n",
    "    # Return array [angle, speed]\n",
    "    return model.predict(x)[0]\n",
    "\n",
    "x_test = load_test()\n",
    "\n",
    "print(x_test[0])\n",
    "\n",
    "predicted_angles = []\n",
    "predicted_speeds = []\n",
    "image_ids = []\n",
    "for image_path in x_test:\n",
    "    prediction = compute_steering_angle(model, read_image(image_path))\n",
    "    \n",
    "    predicted_angles.append(prediction[0])\n",
    "\n",
    "    if prediction[1] < 0.5:\n",
    "        predicted_speeds.append(0)\n",
    "    else:\n",
    "        predicted_speeds.append(1)\n",
    "\n",
    "    image_ids.append(os.path.basename(image_path).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    image_id     angle  speed\n",
      "963        1  0.519215      0\n",
      "887        2  0.752153      1\n",
      "922        3  0.127388      1\n",
      "727        4  0.377400      1\n",
      "772        5  0.092638      1\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsort_keygen\n",
    "\n",
    "data = {\n",
    "    'image_id': image_ids,\n",
    "    'angle': predicted_angles,\n",
    "    'speed': predicted_speeds\n",
    "}\n",
    "results = pd.DataFrame(data)\n",
    "results.sort_values('image_id', inplace=True, key=natsort_keygen())\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770\n",
      "0.59970915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results.at[20, 'image_id'])\n",
    "print(results.at[20, 'angle'])\n",
    "results.at[20, 'speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

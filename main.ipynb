{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__: 2.8.0\n",
      "keras.__version__: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "# python standard libraries\n",
    "import os\n",
    "import random\n",
    "import fnmatch\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential  # V2 is tensorflow.keras.xxxx, V1 is keras.xxx\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "print( f'tf.__version__: {tf.__version__}' )\n",
    "print( f'keras.__version__: {keras.__version__}' )\n",
    "\n",
    "# imaging\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "# sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training():\n",
    "    labels = pd.read_csv('data/training_norm.csv')\n",
    "\n",
    "    images_dir = 'data/training_data/'\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    pattern = '*.png'\n",
    "    for label in labels.itertuples():\n",
    "        filename = str(label.image_id) + '.png'\n",
    "\n",
    "        if fnmatch.fnmatch(filename, pattern):\n",
    "            X.append(os.path.join(images_dir, filename))\n",
    "            Y.append([label.angle, label.speed])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    images_dir = 'data/test_data/'\n",
    "    filenames = os.listdir(images_dir)\n",
    "\n",
    "    paths = []\n",
    "    for filename in filenames:\n",
    "        if fnmatch.fnmatch(filename, '*.png'):\n",
    "            paths.append(os.path.join(images_dir, filename))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nvidia_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 98, 24)        1824      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:16:45.082338: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 47, 36)        21636     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 22, 48)         43248     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 20, 64)         27712     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 20, 64)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 18, 64)         36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               115300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 252,230\n",
      "Trainable params: 252,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def nvidia_model():\n",
    "    model = Sequential(name='Nvidia_Model')\n",
    "    \n",
    "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
    "    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
    "    \n",
    "    # Convolution Layers\n",
    "    model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu')) \n",
    "    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    \n",
    "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # since this is a regression problem not classification problem,\n",
    "    # we use MSE (Mean Squared Error) as loss function\n",
    "    optimizer = Adam(learning_rate=1e-3) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = nvidia_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for NVIDIA model.\n",
    "def img_preprocess(image):\n",
    "    height, _, _ = image.shape\n",
    "    #image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relevant for lane following\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
    "    image = cv2.GaussianBlur(image, (3,3), 0)\n",
    "    image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
    "    image = image / 255 # normalizing\n",
    "    return image\n",
    "\n",
    "def read_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_data_generator(image_paths, angles, batch_size, is_training):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_steering_angles = []\n",
    "\n",
    "        # This works with batches of random images. \n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "\n",
    "            batch_steering_angles.append(angles[random_index])\n",
    "              \n",
    "            image = read_image(image_paths[random_index])\n",
    "            image = img_preprocess(image)\n",
    "            batch_images.append(image)\n",
    "            \n",
    "        yield(np.asarray(batch_images), np.asarray(batch_steering_angles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = 'model_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 11034\n",
      "Validation data: 2759\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0705\n",
      "Epoch 1: val_loss improved from inf to 0.03433, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 360s 1s/step - loss: 0.0705 - val_loss: 0.0343\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0278\n",
      "Epoch 2: val_loss improved from 0.03433 to 0.02648, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 327s 1s/step - loss: 0.0278 - val_loss: 0.0265\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 3: val_loss improved from 0.02648 to 0.02182, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 376s 1s/step - loss: 0.0199 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02182 to 0.01759, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 335s 1s/step - loss: 0.0161 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss did not improve from 0.01759\n",
      "300/300 [==============================] - 365s 1s/step - loss: 0.0130 - val_loss: 0.0196\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 6: val_loss improved from 0.01759 to 0.01676, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 329s 1s/step - loss: 0.0116 - val_loss: 0.0168\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 7: val_loss improved from 0.01676 to 0.01628, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 317s 1s/step - loss: 0.0105 - val_loss: 0.0163\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 8: val_loss improved from 0.01628 to 0.01461, saving model to model_output/lane_navigation_check.h5\n",
      "300/300 [==============================] - 338s 1s/step - loss: 0.0099 - val_loss: 0.0146\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 9: val_loss did not improve from 0.01461\n",
      "300/300 [==============================] - 325s 1s/step - loss: 0.0095 - val_loss: 0.0193\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 10: val_loss did not improve from 0.01461\n",
      "300/300 [==============================] - 297s 991ms/step - loss: 0.0098 - val_loss: 0.0170\n"
     ]
    }
   ],
   "source": [
    "# saves the model weights after each epoch if the validation loss decreased\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(model_output_dir, 'lane_navigation_check.h5'), verbose=1, save_best_only=True)\n",
    "\n",
    "x, y = load_training()\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2)\n",
    "print(\"Training data: %d\\nValidation data: %d\" % (len(x_train), len(x_valid)))\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(image_data_generator(x_train, y_train, batch_size=100, is_training=True),\n",
    "                              steps_per_epoch=300,\n",
    "                              epochs=10,\n",
    "                              validation_data = image_data_generator(x_valid, y_valid, batch_size=100, is_training=False),\n",
    "                              validation_steps=200,\n",
    "                              verbose=1,\n",
    "                              shuffle=1,\n",
    "                              callbacks=[checkpoint_callback, tensorboard_callback])\n",
    "\n",
    "# # always save model output as soon as model finishes training\n",
    "model.save(os.path.join(model_output_dir,'self-drive.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x135649b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='blue')\n",
    "plt.plot(history.history['val_loss'],color='red')\n",
    "plt.legend([\"training loss\", \"validation loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse       = 0.012\n",
      "r_squared = 79.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def summarize_prediction(Y_true, Y_pred):\n",
    "    mse = mean_squared_error(Y_true, Y_pred)\n",
    "    r_squared = r2_score(Y_true, Y_pred)\n",
    "    print(f'mse       = {mse:.2}')\n",
    "    print(f'r_squared = {r_squared:.2%}')\n",
    "    \n",
    "def predict_and_summarize(X, Y):\n",
    "    model = load_model(f'{model_output_dir}/self-drive.h5')\n",
    "    prediction = model.predict(X)\n",
    "    summarize_prediction(Y, prediction)\n",
    "    return prediction\n",
    "\n",
    "n_tests = 100\n",
    "x_test, y_test = next(image_data_generator(x_valid, y_valid, n_tests, False))\n",
    "y_pred = predict_and_summarize(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_data/348.png\n"
     ]
    }
   ],
   "source": [
    "model = load_model(f'{model_output_dir}/self-drive.h5')\n",
    "        \n",
    "def compute_steering_angle(model, frame):\n",
    "    x = np.asarray([img_preprocess(frame)])\n",
    "    \n",
    "    # Return array [angle, speed]\n",
    "    return model.predict(x)[0]\n",
    "\n",
    "x_test = load_test()\n",
    "\n",
    "print(x_test[0])\n",
    "\n",
    "predicted_angles = []\n",
    "predicted_speeds = []\n",
    "image_ids = []\n",
    "for image_path in x_test:\n",
    "    prediction = compute_steering_angle(model, read_image(image_path))\n",
    "    \n",
    "    predicted_angles.append(prediction[0])\n",
    "\n",
    "    if prediction[1] < 0.5:\n",
    "        predicted_speeds.append(0)\n",
    "    else:\n",
    "        predicted_speeds.append(1)\n",
    "\n",
    "    image_ids.append(os.path.basename(image_path).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    image_id     angle  speed\n",
      "963        1  0.592690      0\n",
      "887        2  0.741342      1\n",
      "922        3  0.234167      1\n",
      "727        4  0.027597      1\n",
      "772        5  0.245651      1\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsort_keygen\n",
    "\n",
    "data = {\n",
    "    'image_id': image_ids,\n",
    "    'angle': predicted_angles,\n",
    "    'speed': predicted_speeds\n",
    "}\n",
    "results = pd.DataFrame(data)\n",
    "results.sort_values('image_id', inplace=True, key=natsort_keygen())\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770\n",
      "0.50561786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results.at[20, 'image_id'])\n",
    "print(results.at[20, 'angle'])\n",
    "results.at[20, 'speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
